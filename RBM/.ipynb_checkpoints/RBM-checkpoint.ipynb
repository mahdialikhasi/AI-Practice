{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "training_frame = pd.read_csv(\"./ml-1m/training_set.csv\").values\n",
    "test_frame = pd.read_csv(\"./ml-1m/test_set.csv\").values\n",
    "\n",
    "training_set = {}\n",
    "test_set = {}\n",
    "\n",
    "nb_movies = max(max(training_frame[:,1]), max(test_frame[:,1]))\n",
    "\n",
    "for i in training_frame:\n",
    "    if i[0] not in training_set:\n",
    "        training_set[i[0]] = np.zeros(nb_movies)\n",
    "    training_set[i[0]][i[1] - 1] = i[2]\n",
    "    \n",
    "for i in test_frame:\n",
    "    if i[0] not in test_set:\n",
    "        test_set[i[0]] = np.zeros(nb_movies)\n",
    "    test_set[i[0]][i[1] - 1] = i[2]\n",
    "\n",
    "training_set = np.array(list(training_set.values()))\n",
    "test_set = np.array(list(test_set.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6040, 3952)\n",
      "(6040, 3952)\n"
     ]
    }
   ],
   "source": [
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Data Suitable for RBM\n",
    "\n",
    "training_set[training_set == 0] = -1\n",
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1\n",
    "\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create my RBM class model\n",
    "class RBM():\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = np.random.normal(size=(nh, nv))\n",
    "        self.b = np.random.normal(size=(nv, 1))\n",
    "        self.c = np.random.normal(size=(nh, 1))\n",
    "        self.batch_size = 1\n",
    "        self.rate = 1\n",
    "        self.k = 1\n",
    "    def sigmoid(self, X):\n",
    "       return 1.0/ (1.0 + np.exp(-X))\n",
    "    def sample_h(self, x):\n",
    "        # x is in form of t * nv\n",
    "        activation = np.dot(self.W, np.transpose(x)) + self.c \n",
    "        # p_h_given_v is in form of nh * t, so we transposed it\n",
    "        p_h_given_v = np.transpose(self.sigmoid(activation))        \n",
    "        return p_h_given_v, np.random.binomial(n = 1, p = p_h_given_v) \n",
    "    def sample_v(self, y):\n",
    "        # y is in form of t * nh\n",
    "        activation = np.dot(self.W.transpose(), np.transpose(y)) + self.b \n",
    "        # p_v_given_h is in form of nv * t, so we transposed it\n",
    "        p_v_given_h = np.transpose(self.sigmoid(activation))        \n",
    "        return p_v_given_h, np.random.binomial(n = 1, p = p_v_given_h)\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        # v0, vk is in form of t * nv\n",
    "        # ph0, phk is in form of t * nh\n",
    "        self.W += self.rate * (np.dot(ph0.transpose(), v0) - np.dot(phk.transpose(), vk)) / self.batch_size\n",
    "        self.b += self.rate * (np.dot((v0 - vk).transpose(), np.ones((self.batch_size, 1)))) / self.batch_size\n",
    "        self.c += self.rate * (np.dot((ph0 - phk).transpose(), np.ones((self.batch_size, 1)))) / self.batch_size\n",
    "    def compile(self, rate = 1, k = 2):\n",
    "        self.rate = rate\n",
    "        self.k = k\n",
    "    def loss(self, x):\n",
    "        # v0 is in form of t * nv\n",
    "        vk = x\n",
    "        for k in range(self.k):\n",
    "            _, h = self.sample_h(vk)\n",
    "            _, vk = self.sample_v(h)\n",
    "            # freeze the -1 numbers\n",
    "            vk[x < 0] = x[x < 0]\n",
    "        loss = 0.0\n",
    "        diff = (vk - x)\n",
    "        for i in diff:\n",
    "            loss += (np.dot(i , i.transpose())) / len(i)\n",
    "        loss /= len(x)\n",
    "        return loss\n",
    "    def fit(self, X, batch_size, epochs):\n",
    "        # X is in form of n sample * m feature\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        for i in range(epochs):\n",
    "            print(\"Start Epoch : \", i)\n",
    "            np.random.shuffle(X)\n",
    "            s = 0\n",
    "            loss = 0.0\n",
    "            m = int((len(X) / self.batch_size) / 50)\n",
    "            for j in range(0, len(X) - self.batch_size, self.batch_size):\n",
    "                v0 = X[j:j + batch_size]\n",
    "                vk = v0\n",
    "                for k in range(self.k):\n",
    "                    _, h = self.sample_h(vk)\n",
    "                    _, vk = self.sample_v(h)\n",
    "                    # freeze the -1 numbers\n",
    "                    vk[v0 < 0] = v0[v0 < 0]\n",
    "                ph0,_ = self.sample_h(v0)\n",
    "                phk,_ = self.sample_h(vk)\n",
    "                self.train(v0, vk, ph0, phk)\n",
    "                loss += self.loss(v0)\n",
    "                \n",
    "                s += 1\n",
    "                if(s % m == 0):\n",
    "                    print(\"#\",end='')\n",
    "            print(\"\\nloss : \", loss / s) \n",
    "    def predict(self, X):\n",
    "        # X is in form of n sample * m feature\n",
    "        for i in range(len(X)):\n",
    "            _, h = self.sample_h(X[i])\n",
    "            _, X[i] = self.sample_v(h)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Epoch :  0\n",
      "##############################################################\n",
      "loss :  0.007811616727862005\n",
      "Start Epoch :  1\n",
      "##############################################################\n",
      "loss :  0.007141928204948744\n",
      "Start Epoch :  2\n",
      "##############################################################\n",
      "loss :  0.007038921849427168\n",
      "Start Epoch :  3\n",
      "##############################################################\n",
      "loss :  0.007024032404815227\n",
      "Start Epoch :  4\n",
      "##############################################################\n",
      "loss :  0.006968260078387458\n",
      "Start Epoch :  5\n",
      "##############################################################\n",
      "loss :  0.006946346517249546\n",
      "Start Epoch :  6\n",
      "##############################################################\n",
      "loss :  0.006948028940369543\n",
      "Start Epoch :  7\n",
      "##############################################################\n",
      "loss :  0.006987103217331383\n",
      "Start Epoch :  8\n",
      "##############################################################\n",
      "loss :  0.00695538954151951\n",
      "Start Epoch :  9\n",
      "##############################################################\n",
      "loss :  0.006962287476311486\n"
     ]
    }
   ],
   "source": [
    "# create model and train it\n",
    "\n",
    "rbm = RBM(len(training_set[0]), 100)\n",
    "rbm.compile(rate = 1, k = 5)\n",
    "rbm.fit(training_set, batch_size = 32, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-c7abd5581eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# predict our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_set\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_set\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-d5d847b30627>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# X is in form of n sample * m feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# predict our model\n",
    "y = rbm.predict(test_set)\n",
    "loss = np.mean(np.abs(training_set[training_set >= 0] - y[training_set >= 0]))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = training_set[2]\n",
    "a = a[a >= 0]\n",
    "\n",
    "b = test_set[2]\n",
    "b = b[b >= 0]\n",
    "\n",
    "c = y[2]\n",
    "c = c[c >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in c:\n",
    "    i += 1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
